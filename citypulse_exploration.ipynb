# %% [markdown]
# # CityPulse: Interactive Exploration Notebook
# 
# This notebook provides an interactive environment for exploring the CityPulse implementation,
# visualizing results, and experimenting with the change detection model.

# %% [markdown]
# ## 1. Setup and Imports

# %%
import os
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from IPython.display import display, HTML, Image as IPImage
import ipywidgets as widgets
from ipywidgets import interact, interactive, fixed
import folium
from folium import plugins
import warnings
warnings.filterwarnings('ignore')

# Import our modules
import sys
sys.path.append('..')  # Adjust path as needed

from citypulse_implementation import (
    Config, StreetViewTimeSeriesDataset, DINOv2Backbone,
    SiameseChangeDetector, ChangeDetectionTrainer, UrbanChangeAnalyzer
)
from visualizer import CityPulseVisualizer
from evaluation import CityPulseEvaluator

# Set style
plt.style.use('seaborn-v0_8-darkgrid')
%matplotlib inline

# %% [markdown]
# ## 2. Load and Explore Data

# %%
# Load sample data
data_path = os.path.join(Config.DATA_DIR, 'test_data.json')

if os.path.exists(data_path):
    with open(data_path, 'r') as f:
        test_data = json.load(f)
    print(f"Loaded {len(test_data)} time series")
else:
    print("No data found. Run citypulse_implementation.py first to generate data.")
    test_data = []

# %%
# Explore data structure
if test_data:
    sample_series = test_data[0]
    print("Sample time series structure:")
    print(f"Location ID: {sample_series['location_id']}")
    print(f"City: {sample_series['city']}")
    print(f"Number of images: {len(sample_series['images'])}")
    print(f"Years covered: {[img['year'] for img in sample_series['images']]}")
    print(f"Change points: {sample_series.get('change_points', [])}")

# %%
# Data statistics
if test_data:
    df_stats = pd.DataFrame([
        {
            'city': series['city'],
            'n_images': len(series['images']),
            'has_changes': len(series.get('change_points', [])) > 0,
            'n_changes': len(series.get('change_points', [])),
            'year_span': series['images'][-1]['year'] - series['images'][0]['year']
        }
        for series in test_data
    ])
    
    # City-wise statistics
    city_stats = df_stats.groupby('city').agg({
        'n_images': ['mean', 'min', 'max'],
        'has_changes': 'mean',
        'n_changes': 'mean',
        'year_span': 'mean'
    }).round(2)
    
    display(HTML("<h3>City-wise Statistics</h3>"))
    display(city_stats)
    
    # Visualize distribution
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    
    # Images per series
    df_stats['n_images'].hist(ax=axes[0, 0], bins=20, edgecolor='black')
    axes[0, 0].set_title('Distribution of Images per Time Series')
    axes[0, 0].set_xlabel('Number of Images')
    
    # Changes per series
    df_stats['n_changes'].hist(ax=axes[0, 1], bins=10, edgecolor='black')
    axes[0, 1].set_title('Distribution of Change Points')
    axes[0, 1].set_xlabel('Number of Changes')
    
    # Percentage with changes by city
    city_changes = df_stats.groupby('city')['has_changes'].mean() * 100
    city_changes.plot(kind='bar', ax=axes[1, 0])
    axes[1, 0].set_title('Percentage of Locations with Changes by City')
    axes[1, 0].set_ylabel('Percentage (%)')
    axes[1, 0].tick_params(axis='x', rotation=45)
    
    # Year span distribution
    df_stats['year_span'].hist(ax=axes[1, 1], bins=15, edgecolor='black')
    axes[1, 1].set_title('Distribution of Year Spans')
    axes[1, 1].set_xlabel('Years Covered')
    
    plt.tight_layout()
    plt.show()

# %% [markdown]
# ## 3. Interactive Time Series Explorer

# %%
def explore_time_series(series_index):
    """Interactive widget to explore individual time series"""
    if not test_data:
        print("No data available")
        return
    
    series = test_data[series_index]
    n_images = len(series['images'])
    
    fig, axes = plt.subplots(2, 5, figsize=(15, 6))
    fig.suptitle(f"Time Series: {series['location_id']} ({series['city']})", fontsize=16)
    
    # Plot images
    for i, (ax, img_data) in enumerate(zip(axes.flat, series['images'])):
        # Create placeholder image
        ax.text(0.5, 0.5, str(img_data['year']), 
                ha='center', va='center', fontsize=20)
        
        # Highlight change points
        if img_data['year'] in series.get('change_points', []):
            ax.set_facecolor('#ffcccc')
            ax.set_title(f"CHANGE - {img_data['year']}", color='red', weight='bold')
        else:
            ax.set_facecolor('#cccccc')
            ax.set_title(str(img_data['year']))
            
        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1)
        ax.set_xticks([])
        ax.set_yticks([])
    
    # Hide unused subplots
    for i in range(n_images, 10):
        axes.flat[i].axis('off')
    
    plt.tight_layout()
    plt.show()
    
    # Print details
    print(f"\nDetails:")
    print(f"Location: ({series.get('lat', 'N/A')}, {series.get('lon', 'N/A')})")
    print(f"Total images: {n_images}")
    print(f"Change points: {series.get('change_points', [])}")

# Create interactive widget
if test_data:
    interact(explore_time_series, 
             series_index=widgets.IntSlider(min=0, max=len(test_data)-1, 
                                           step=1, value=0,
                                           description='Series:'))

# %% [markdown]
# ## 4. Model Loading and Evaluation

# %%
# Load trained model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

model_path = os.path.join(Config.MODEL_DIR, 'best_model.pth')
if os.path.exists(model_path):
    # Initialize model
    backbone = DINOv2Backbone()
    model = SiameseChangeDetector(backbone).to(device)
    
    # Load weights
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    print("Model loaded successfully!")
else:
    print("No trained model found. Run training first.")
    model = None

# %%
# Test model on sample pairs
if model and test_data:
    # Create a small test dataset
    transform = transforms.Compose([
        transforms.Resize(Config.IMAGE_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    # Get a few sample pairs
    sample_pairs = []
    for series in test_data[:5]:
        images = series['images']
        if len(images) >= 2:
            # Get one change and one no-change pair if possible
            change_points = series.get('change_points', [])
            
            # Find a change pair
            for i in range(len(images) - 1):
                if images[i]['year'] in change_points:
                    sample_pairs.append({
                        'series': series['location_id'],
                        'year1': images[i]['year'],
                        'year2': images[i+1]['year'],
                        'label': 1
                    })
                    break
            
            # Add a no-change pair
            if len(change_points) == 0:
                sample_pairs.append({
                    'series': series['location_id'],
                    'year1': images[0]['year'],
                    'year2': images[-1]['year'],
                    'label': 0
                })
    
    # Make predictions
    print("Sample Predictions:")
    print("-" * 60)
    
    with torch.no_grad():
        for pair in sample_pairs[:5]:
            # Create dummy images for demo
            img1 = Image.new('RGB', (640, 640), color='white')
            img2 = Image.new('RGB', (640, 640), color='white')
            
            # Transform
            img1_tensor = transform(img1).unsqueeze(0).to(device)
            img2_tensor = transform(img2).unsqueeze(0).to(device)
            
            # Predict
            output = model(img1_tensor, img2_tensor)
            prob = output.item()
            pred = 1 if prob > 0.5 else 0
            
            print(f"Series: {pair['series']}")
            print(f"Years: {pair['year1']} â†’ {pair['year2']}")
            print(f"True label: {'Change' if pair['label'] == 1 else 'No change'}")
            print(f"Prediction: {'Change' if pred == 1 else 'No change'} (prob: {prob:.3f})")
            print("-" * 60)

# %% [markdown]
# ## 5. Interactive Map Visualization

# %%
def create_interactive_map(city='Seattle'):
    """Create interactive map for a city"""
    
    # Filter data for city
    city_data = [s for s in test_data if s['city'] == city]
    
    if not city_data:
        print(f"No data for {city}")
        return None
    
    # City centers
    city_centers = {
        'Seattle': [47.6062, -122.3321],
        'San Francisco': [37.7749, -122.4194],
        'Oakland': [37.8044, -122.2712],
        'Los Angeles': [34.0522, -118.2437],
        'Boston': [42.3601, -71.0589]
    }
    
    # Create map
    m = folium.Map(location=city_centers.get(city, [0, 0]), 
                   zoom_start=12, tiles='OpenStreetMap')
    
    # Add markers for each location
    for series in city_data:
        # Use approximate coordinates
        lat = 47.6 + np.random.uniform(-0.2, 0.2)  # Random for demo
        lon = -122.3 + np.random.uniform(-0.2, 0.2)
        
        # Determine marker color based on changes
        n_changes = len(series.get('change_points', []))
        if n_changes == 0:
            color = 'green'
            icon = 'check'
        elif n_changes == 1:
            color = 'orange'
            icon = 'exclamation'
        else:
            color = 'red'
            icon = 'exclamation-triangle'
        
        # Create popup text
        popup_text = f"""
        <b>Location:</b> {series['location_id']}<br>
        <b>Images:</b> {len(series['images'])}<br>
        <b>Years:</b> {series['images'][0]['year']} - {series['images'][-1]['year']}<br>
        <b>Changes:</b> {n_changes}<br>
        <b>Change Years:</b> {', '.join(map(str, series.get('change_points', [])))}
        """
        
        folium.Marker(
            location=[lat, lon],
            popup=folium.Popup(popup_text, max_width=300),
            icon=folium.Icon(color=color, icon=icon, prefix='fa')
        ).add_to(m)
    
    # Add legend
    legend_html = '''
    <div style="position: fixed; 
                top: 50px; right: 50px; width: 200px; height: 120px; 
                background-color: white; z-index:9999; font-size:14px;
                border:2px solid grey; border-radius: 5px; padding: 10px">
    <p><i class="fa fa-check" style="color:green"></i> No changes detected</p>
    <p><i class="fa fa-exclamation" style="color:orange"></i> 1 change detected</p>
    <p><i class="fa fa-exclamation-triangle" style="color:red"></i> Multiple changes</p>
    </div>
    '''
    m.get_root().html.add_child(folium.Element(legend_html))
    
    return m

# Create maps for each city
city_selector = widgets.Dropdown(
    options=['Seattle', 'San Francisco', 'Oakland', 'Los Angeles', 'Boston'],
    value='Seattle',
    description='City:'
)

def update_map(city):
    map_obj = create_interactive_map(city)
    if map_obj:
        display(map_obj)

interact(update_map, city=city_selector)

# %% [markdown]
# ## 6. Performance Analysis

# %%
# Load evaluation results if available
eval_results_dir = './evaluation_results'

if os.path.exists(eval_results_dir):
    # Load backbone comparison
    backbone_df = pd.read_csv(os.path.join(eval_results_dir, 'backbone_comparison.csv'))
    
    # Visualize backbone comparison
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
    
    # Linear probing results
    metrics = ['LP_Accuracy', 'LP_Precision', 'LP_Recall', 'LP_F1']
    backbone_df.set_index('Model')[metrics].plot(kind='bar', ax=ax1)
    ax1.set_title('Linear Probing Performance')
    ax1.set_ylabel('Score')
    ax1.set_ylim(0.5, 1.0)
    ax1.legend(['Accuracy', 'Precision', 'Recall', 'F1'])
    ax1.tick_params(axis='x', rotation=45)
    
    # Fine-tuning results
    metrics = ['FT_Accuracy', 'FT_Precision', 'FT_Recall', 'FT_F1']
    backbone_df.set_index('Model')[metrics].plot(kind='bar', ax=ax2)
    ax2.set_title('Fine-Tuning Performance')
    ax2.set_ylabel('Score')
    ax2.set_ylim(0.5, 1.0)
    ax2.legend(['Accuracy', 'Precision', 'Recall', 'F1'])
    ax2.tick_params(axis='x', rotation=45)
    
    plt.suptitle('Backbone Model Comparison', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    # Best model
    best_model = backbone_df.loc[backbone_df['FT_F1'].idxmax()]
    print(f"\nBest Model: {best_model['Model']}")
    print(f"F1 Score: {best_model['FT_F1']:.3f}")

# %% [markdown]
# ## 7. Change Detection Demo

# %%
class ChangeDetectionDemo:
    """Interactive demo for change detection"""
    
    def __init__(self, model, device):
        self.model = model
        self.device = device
        self.transform = transforms.Compose([
            transforms.Resize(Config.IMAGE_SIZE),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
    
    def predict_change(self, img1_path, img2_path):
        """Predict change between two images"""
        # Load images
        img1 = Image.open(img1_path) if os.path.exists(img1_path) else Image.new('RGB', (640, 640), 'white')
        img2 = Image.open(img2_path) if os.path.exists(img2_path) else Image.new('RGB', (640, 640), 'white')
        
        # Transform
        img1_tensor = self.transform(img1).unsqueeze(0).to(self.device)
        img2_tensor = self.transform(img2).unsqueeze(0).to(self.device)
        
        # Predict
        with torch.no_grad():
            output = self.model(img1_tensor, img2_tensor)
            prob = output.item()
        
        return prob
    
    def visualize_prediction(self, img1_path, img2_path, show_heatmap=False):
        """Visualize prediction with optional attention heatmap"""
        prob = self.predict_change(img1_path, img2_path)
        prediction = "CHANGE DETECTED" if prob > 0.5 else "NO CHANGE"
        
        # Create visualization
        fig, axes = plt.subplots(1, 3 if show_heatmap else 2, figsize=(15 if show_heatmap else 10, 5))
        
        # Image 1
        img1 = Image.open(img1_path) if os.path.exists(img1_path) else Image.new('RGB', (640, 640), 'lightgray')
        axes[0].imshow(img1)
        axes[0].set_title('Before')
        axes[0].axis('off')
        
        # Image 2
        img2 = Image.open(img2_path) if os.path.exists(img2_path) else Image.new('RGB', (640, 640), 'darkgray')
        axes[1].imshow(img2)
        axes[1].set_title('After')
        axes[1].axis('off')
        
        # Heatmap (if requested)
        if show_heatmap:
            # Create difference heatmap
            arr1 = np.array(img1.convert('L'))
            arr2 = np.array(img2.convert('L'))
            diff = np.abs(arr1.astype(float) - arr2.astype(float))
            
            im = axes[2].imshow(diff, cmap='hot')
            axes[2].set_title('Difference Heatmap')
            axes[2].axis('off')
            plt.colorbar(im, ax=axes[2], fraction=0.046)
        
        # Add prediction
        fig.suptitle(f'{prediction} (Confidence: {prob:.1%})', 
                    fontsize=16, 
                    color='red' if prob > 0.5 else 'green',
                    weight='bold')
        
        plt.tight_layout()
        plt.show()

# Create demo instance
if model:
    demo = ChangeDetectionDemo(model, device)
    
    # Demo with dummy images
    print("Change Detection Demo")
    print("(Using placeholder images for demonstration)")
    
    # Create dummy image paths
    dummy_path1 = "dummy_before.jpg"
    dummy_path2 = "dummy_after.jpg"
    
    # Run demo
    demo.visualize_prediction(dummy_path1, dummy_path2, show_heatmap=True)

# %% [markdown]
# ## 8. Export Results

# %%
def export_results(output_dir='./notebook_results'):
    """Export analysis results"""
    os.makedirs(output_dir, exist_ok=True)
    
    if test_data:
        # Export summary statistics
        summary = {
            'total_series': len(test_data),
            'cities': list(set(s['city'] for s in test_data)),
            'series_with_changes': sum(1 for s in test_data if s.get('change_points')),
            'total_changes': sum(len(s.get('change_points', [])) for s in test_data),
            'avg_images_per_series': np.mean([len(s['images']) for s in test_data])
        }
        
        with open(os.path.join(output_dir, 'summary_stats.json'), 'w') as f:
            json.dump(summary, f, indent=2)
        
        print("Results exported to:", output_dir)
        print("\nSummary:")
        for key, value in summary.items():
            print(f"  {key}: {value}")

# Export results
export_results()

# %% [markdown]
# ## 9. Next Steps
# 
# 1. **Collect Real Data**: Use `data_collector.py` to collect real Google Street View data
# 2. **Label Changes**: Use the annotation tools to label actual urban changes
# 3. **Train Custom Models**: Experiment with different architectures and pre-training strategies
# 4. **Deploy**: Use the Docker container for production deployment
# 5. **Extend**: Add new features like change type classification or severity estimation

# %%
print("Notebook execution complete!")
print("\nFor questions or contributions, please refer to the GitHub repository.")
